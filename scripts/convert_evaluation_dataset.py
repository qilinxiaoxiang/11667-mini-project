#!/usr/bin/env python3
"""
Convert plain evaluation dataset to hierarchical format.

Takes the evaluation dataset generated by generate_evaluation_dataset.py
and converts plain doctor responses to hierarchical structure using DeepSeek API.

This uses the same conversion logic as convert_dataset.py but for evaluation data.
"""
import sys
import os

# Add project root to path
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.converter import HierarchicalConverter
from src.processor import DatasetProcessor
from config import settings
from datasets import load_from_disk, Dataset
from multiprocessing import Pool
from tqdm import tqdm
from typing import Tuple, Dict, List


def process_evaluation_example(args: Tuple[int, Dict]) -> Tuple[int, Dict]:
    """
    Convert a single evaluation sample to hierarchical format.

    Args:
        args: Tuple of (index, example)

    Returns:
        Tuple of (index, processed_example)
    """
    idx, example = args

    # Create converter in worker process
    converter = HierarchicalConverter()

    # Get plain doctor response
    plain_doctor = example['Doctor']

    # Convert to hierarchical format
    hierarchical_doctor = converter.convert(plain_doctor)

    # Prepare processed example (keep same structure)
    processed = {
        'Description': example['Description'],
        'Doctor': hierarchical_doctor if hierarchical_doctor else plain_doctor,
        'Patient': example['Patient'],
        'Status': example['Status'],
        '_original_doctor': plain_doctor,  # Keep original for comparison
        '_conversion_success': hierarchical_doctor is not None
    }

    return idx, processed


def convert_evaluation_dataset(input_path: str, output_path: str = None):
    """
    Convert evaluation dataset from plain to hierarchical doctor responses.

    Args:
        input_path: Path to input dataset (plain responses)
        output_path: Path to save converted dataset (hierarchical responses)
    """
    # Check API key
    if not settings.DEEPSEEK_API_KEY:
        print("❌ Error: DEEPSEEK_API_KEY not found in environment variables!")
        print("Please set it in ~/.zshrc or ~/.bashrc:")
        print("  export DEEPSEEK_API_KEY='your_api_key_here'")
        sys.exit(1)

    print("\n" + "="*80)
    print("EVALUATION DATASET CONVERSION (Plain → Hierarchical)")
    print("="*80 + "\n")

    # Load evaluation dataset
    print("Step 1: Loading evaluation dataset...")
    try:
        dataset = load_from_disk(input_path)
        print(f"✓ Loaded {len(dataset)} evaluation samples\n")
    except Exception as e:
        print(f"❌ Error loading dataset: {e}")
        sys.exit(1)

    print(f"Configuration:")
    print(f"  Model:        {settings.DEEPSEEK_MODEL}")
    print(f"  Workers:      {settings.MAX_WORKERS}")
    print(f"  Input:        {input_path}")
    print(f"  Output:       {output_path or input_path + '_hierarchical'}")
    print()

    # Set output path
    if output_path is None:
        output_path = input_path.replace('evaluation_dataset_synthetic',
                                        'evaluation_dataset_hierarchical')

    # Convert dataset
    print("Step 2: Converting to hierarchical format...\n")

    results = []
    args_list = [(idx, example) for idx, example in enumerate(dataset)]

    with Pool(processes=settings.MAX_WORKERS) as pool:
        with tqdm(total=len(dataset), desc="Converting", ncols=80) as pbar:
            for idx, result in pool.imap_unordered(process_evaluation_example, args_list):
                results.append((idx, result))
                pbar.update(1)

                # Update success rate
                all_results_so_far = [r[1] for r in results]
                success_count = sum(r['_conversion_success'] for r in all_results_so_far)
                success_rate = success_count / len(all_results_so_far) * 100
                pbar.set_postfix({'success': f'{success_rate:.1f}%'})

    # Sort by index
    results.sort(key=lambda x: x[0])
    all_results = [r[1] for r in results]

    # Create HuggingFace dataset
    print("\nStep 3: Creating HuggingFace dataset...\n")
    data = {
        'Description': [r['Description'] for r in all_results],
        'Doctor': [r['Doctor'] for r in all_results],
        'Patient': [r['Patient'] for r in all_results],
        'Status': [r['Status'] for r in all_results],
        '_original_doctor': [r['_original_doctor'] for r in all_results],
        '_conversion_success': [r['_conversion_success'] for r in all_results],
    }
    converted_dataset = Dataset.from_dict(data)

    # Save dataset
    print(f"Step 4: Saving converted dataset...\n")
    os.makedirs(os.path.dirname(output_path) or ".", exist_ok=True)
    converted_dataset.save_to_disk(output_path)
    print(f"✓ Dataset saved to: {output_path}\n")

    # Print statistics
    success_count = sum(r['_conversion_success'] for r in all_results)
    fail_count = len(all_results) - success_count

    print("="*80)
    print("✓ Conversion Complete!")
    print("="*80)
    print(f"Total processed:      {len(all_results)}")
    print(f"Successful:           {success_count} ({success_count/len(all_results)*100:.2f}%)")
    print(f"Failed (kept plain):  {fail_count} ({fail_count/len(all_results)*100:.2f}%)")

    # Show sample
    print(f"\n{'='*80}")
    print("Sample converted result:")
    print(f"{'='*80}")
    sample = all_results[0]
    print(f"Description: {sample['Description']}")
    print(f"\nPatient: {sample['Patient'][:150]}...")
    print(f"\nDoctor (Hierarchical):\n{sample['Doctor'][:500]}...")
    print(f"\nStatus: {sample['Status']}")
    print(f"Conversion success: {sample['_conversion_success']}")
    print("="*80 + "\n")

    print("✅ Evaluation dataset converted to hierarchical format!\n")

    return converted_dataset


def main():
    """Main execution function."""
    import argparse

    parser = argparse.ArgumentParser(
        description="Convert evaluation dataset from plain to hierarchical doctor responses"
    )
    parser.add_argument(
        "--input",
        type=str,
        default=None,
        help="Input dataset path (plain responses)"
    )
    parser.add_argument(
        "--output",
        type=str,
        default=None,
        help="Output dataset path (hierarchical responses)"
    )

    args = parser.parse_args()

    # Set default input path if not specified
    input_path = args.input or os.path.join(
        settings.PROCESSED_DATA_DIR,
        "evaluation_dataset_synthetic"
    )

    # Convert dataset
    convert_evaluation_dataset(input_path, args.output)


if __name__ == "__main__":
    main()
