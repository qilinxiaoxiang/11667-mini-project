\documentclass{article}

\usepackage[margin=1in]{geometry}
\usepackage{graphicx}
\usepackage{fancyvrb}
\usepackage{fvextra}
\usepackage{xcolor}
\definecolor{mauve}{rgb}{0.58,0,0.82}
\usepackage{titlesec}
\usepackage[scaled=0.96]{helvet} % Sets up Helvetica font
\usepackage{amsmath}
\usepackage{listings}
\usepackage{hyperref}
\usepackage{booktabs}
\usepackage{float}
\usepackage{tcolorbox}
\tcbuselibrary{skins,breakable}

\newtcolorbox{promptbox}[2][]{%
  breakable,
  colback=gray!5,
  colframe=gray!60,
  boxrule=0.5pt,
  arc=1mm,
  left=1mm, right=1mm, top=1mm, bottom=1mm,
  title={#2},    % 标题文本
  #1             % 其他可选参数
}
\titleformat{\section}[hang]{\color{mauve}\normalfont\sffamily\Large}{\thesection}{1em}{}
\titleformat{\subsection}[hang]{\color{mauve}\normalfont\sffamily\large}{\thesubsection}{1em}{}

\title{Mini Project}
\author{Xinshi Wang (xinshiw), Shawn Xiang (zhengxia)}

\begin{document}
\maketitle
\section{Problem 1: Picking a Task and a Dataset}
\subsection{Task Description and Motivation} 
We propose generating medical and nutrition answers in MECE-structured hierarchical form from patient questions using small LLM , which improves readability and downstream automation.\\
This task is interesting because it requires structured generation, medical reasoning, and information organization without performing diagnosis. Compared with standard summarization or QA, our task forces models to (1) identify relevant clinical/nutritional factors, (2) group them into non-overlapping categories, and (3) produce results in hierarchical and consistent format.

\subsection{Data Description}
Our dataset contains patient medical questions paired with gold MECE-structured answers constructed from original doctor answers. We constructed a dataset of 3311 examples using LLM based on the following open source dataset on hugging face. \href{https://huggingface.co/datasets/lavita/ChatDoctor-HealthCareMagic-100k/viewer/default/train?views%5B%5D=train&row=5}{ChatDoctor-HealthCareMagic-100k}\\
Example data point:
\begin{Verbatim}[fontsize=\small, breaklines=true, breakanywhere=true]
Input:
Hi doctor, my mom (45 years old) has had evening fevers for two months, bone pain, and weight loss. She was advised calcium and iron tablets. What should we do?

Output:
- **1. Clinical presentation**
  - **1.1 Fever pattern**
    - Evening low-grade fever for ~2 months
  - **1.2 Associated symptoms**
    - Bone pain
    - Weight loss
- **2. Possible underlying causes**
  - **2.1 Infectious possibilities**
    - Consider chronic infections such as tuberculosis
- **3. Recommended investigations**
  - **3.1 Screening tests**
    - CBC, ESR/CRP
- **4. Supportive care**
  - **4.1 Hydration & nutrition**
- **5. Follow-up**
\end{Verbatim}

\subsection{Ethical Considerations}
The dataset contains medical-related text, which contains several ethical issues:
\begin{enumerate}
    \item Safety and risk of misuse:
The original gold answers explicitly avoid definitive diagnosis and focus on supportive guidance. Our gold MECE style answers also follow the same guideline as it is generated from the original gold answer.
    \item Bias in data collection:
Medical questions may reflect demographic skew like regional writing styles, or contains conditions that are more common in certain populations. This may influence model behavior.
    \item Sensitive information:
Sensitive information was already removed in the original gold answer. Since our gold MECE style answers were generated from the original dataset, we do not forsee this issue.
\end{enumerate}

\subsection{Formulation of Training Data}

\subsection{Method for evaluation}
We evaluate model outputs using both text-level and structure-level metrics designed for hierarchical MECE-style medical responses.

\subsubsection*{Text-Level Metrics}
To quantify surface similarity between predictions and references, we use:
\begin{itemize}
    \item \textbf{String Similarity}: token-level normalized Levenshtein similarity.
    \item \textbf{ROUGE-L}: longest-common-subsequence F-score.
    \item \textbf{BLEU}: n-gram precision with smoothing.
\end{itemize}
These metrics capture lexical overlap but do not reflect structural quality.
\subsubsection*{Structure-Level Metrics (Pyramid / MECE Quality)}
Because the task requires generation of a multi-level MECE hierarchy, we compute structure-aware metrics:
\begin{itemize}
    \item \textbf{Depth Score}: full credit if max depth $\ge 3$, otherwise proportional to (depth / 3).
    \item \textbf{Constraint Score}: proportion of parent nodes whose number of children does not exceed 5.
    \item \textbf{Grouping Score}: evaluates organizational quality:
    \begin{itemize}
        \item 3--5 children: 1.0 (optimal)
        \item 2 children: 0.9
        \item 1 child: 0.5
        \item $>5$ children: 0.0
    \end{itemize}
    \item \textbf{MECE Score}: aggregated structural score with weights:
    \[
        \text{MECE Score}
        = 0.4 \cdot \text{Constraint}
        + 0.4 \cdot \text{Grouping}
        + 0.2 \cdot \text{Depth}.
    \]
\end{itemize}

\subsubsection*{Overall Evaluation Pipeline}
For each prediction--reference pair, we compute:
\begin{itemize}
    \item string similarity,\ rouge-L,\ BLEU
    \item depth score,\ constraint score,\ grouping score
    \item MECE compliance,\ MECE score
    \item structural statistics (max depth, total node count)
\end{itemize}

\section{Problem 2: Adapting a Language Model to your Task}
\subsection{Train-Test Split}
We first divide our data set into train, eval, and test, where train contains 1 sample for oneshot, 3 samples for fewshots, and 332 samples for tests. Here are the results for the three propt methods. 

\subsection{A. Method for in-context learning.}
For ICL, we came up with three approachs, namely base oneshot/few shots, detailed fewshots, and CoT fewshots.



\subsubsection{Base Prompt results on evaluation set}

We first evaluate the onshot/few shots version of the Base prompt on the evaluation set, here's the prompt we used:
\begin{promptbox}[label={base prompt oneshot/fewshots}]{Base prompt used}
system: You are an advanced medical AI assistant specialized in structured reasoning. Your task is to analyze patient queries and provide comprehensive, MECE (Mutually Exclusive, Collectively Exhaustive) hierarchical responses.

=== OUTPUT FORMAT (STRICT) ===
- **1. $<$Top-level section$>$**
  - **1.1 $<$Subsection$>$**
    - $<$bullet$>$
    - $<$bullet$>$
- **2. $<$Top-level section$>$**
  ...
Rules:
A) Use MECE structure in each level.
B) No diagnosis; only plausible causes + safe advice.
C) No extra text before/after hierarchy.

=== EXAMPLE ===
Input: hi doctor my mom aged 45 years is having a fever for almost two months the temperature used to vary from 100 degrees celsius in the night times and gradually it comes down she was weighing 105 keg and now she is keg now she is having bone pain and light fever in the night when there is a pain in the bone she has been advised with calcium and iron tablets she is also getting her regular periods menopause has not reached yet kindly advise

Output (EXACT FORMAT TO FOLLOW):
- **1. Clinical Presentation Suggestive of Tuberculosis**
    - (output abbreviated)
Input: hi doctor I am having a problem with sinusitis my doctor ordered me to take co altria 10 my at bedtime I have taken it at am and currently I am experiencing dryness of mouth and headache what to do is this serious I am also taking cefixime 200 my twice daily sinupret thrice daily and nasoflo spray

Output:
- **1. Primary Cause of Dry Mouth**
    - (output abbreviated)
    
Input: hello doctor I have erosion in my stomach severe burning sensation and sometimes vomiting and bloating I have done endoscopy colonoscopy angiography and hospitalized for about four times recently again I have done endoscopy found astral erosion please advice

Output:
- **1. Treatment Plan for Gastric Erosion and Ulceration**
  - (output abbreviated)
    
=== NOW DO THIS ===
Input: {{question}}
Output:"""
\end{promptbox}
Here's the result of oneshot vs fewshots of base prompt on evaluation dataset:
\begin{figure}[H]
    \includegraphics[width = 0.6\textwidth]{base-icl-score.png}
    \includegraphics[width = 0.4\textwidth]{base-generation-time.png}
\end{figure}
Since the fewshots base model performs much better on the evaluation set compared to oneshot model, we will use few shots for the rest of the prompts.

\begin{promptbox}[label={detailed prompt}]{Detailed prompt used}
system: You are an advanced medical AI assistant specialized in structured reasoning. Your task is to analyze patient queries and provide comprehensive, MECE (Mutually Exclusive, Collectively Exhaustive) hierarchical responses.

=== STRICT OUTPUT FORMAT ===
You must strictly follow this Markdown structure. Do not include any introductory or concluding text. Start directly with the first bullet point.

- **1. $<$Main Category$>$**
  - **1.1 $<$Sub-category$>$**
    - $<$Specific detail or actionable advice$>$
    - $<$Specific detail or actionable advice$>$
  - **1.2 $<$Sub-category$>$**
    - $<$Specific detail$>$
- **2. $<$Main Category$>$**
  ...

=== CRITICAL RULES ===
1. **Structure**:
   - Use exactly 3 levels of hierarchy: Main Category $->$ Sub-category $->$ Details.
   - Each Main Category must have at least 2 Sub-categories.
   - Each Sub-category must have at least 2 Detail bullets.
   - Use bolding for Level 1 and Level 2 headers (e.g., **1. Analysis**).

2. **MECE Principle**:
   - Ensure all categories at the same level are mutually exclusive (no overlap).
   - Ensure categories collectively cover all relevant aspects of the query (collectively exhaustive).

3. **Content Safety**:
   - NEVER provide a definitive diagnosis. Use phrases like "Plausible causes", "Possible contributing factors".
   - Provide safe, general medical advice and lifestyle recommendations.
   - Always recommend consulting a healthcare provider for specific issues.

4. **Formatting**:
   - Output **ONLY** the hierarchical list.
   - NO "Here is the answer:" or "Summary:".
   - NO "Hope this helps!" at the end.
   
=== EXAMPLE ===
Input: hi doctor my mom aged 45 years is having a fever for almost two months the temperature used to vary from 100 degrees celsius in the night times and gradually it comes down she was weighing 105 keg and now she is keg now she is having bone pain and light fever in the night when there is a pain in the bone she has been advised with calcium and iron tablets she is also getting her regular periods menopause has not reached yet kindly advise

Output (EXACT FORMAT TO FOLLOW):
- **1. Clinical Presentation Suggestive of Tuberculosis**
    - (output abbreviated)
Input: hi doctor I am having a problem with sinusitis my doctor ordered me to take co altria 10 my at bedtime I have taken it at am and currently I am experiencing dryness of mouth and headache what to do is this serious I am also taking cefixime 200 my twice daily sinupret thrice daily and nasoflo spray

Output:
- **1. Primary Cause of Dry Mouth**
    - (output abbreviated)
    
Input: hello doctor I have erosion in my stomach severe burning sensation and sometimes vomiting and bloating I have done endoscopy colonoscopy angiography and hospitalized for about four times recently again I have done endoscopy found astral erosion please advice

Output:
- **1. Treatment Plan for Gastric Erosion and Ulceration**
  - (output abbreviated)
    
=== NOW DO THIS ===
Input: {{question}}
\end{promptbox}


\begin{promptbox}[label={CoT prompt}]{CoT prompt used}
System: You are a medical AI assistant that analyzes patient queries using structured reasoning. You MUST follow these exact steps to create a MECE (Mutually Exclusive, Collectively Exhaustive) hierarchical response.

=== STEP-BY-STEP INSTRUCTIONS (FOLLOW EXACTLY) ===

STEP 1: READ AND ANALYZE
- Read the patient's question carefully
- Identify all key symptoms, concerns, and medical information mentioned
- Note any medications, test results, or prior treatments mentioned

STEP 2: CATEGORIZE USING MECE PRINCIPLE
- Divide the patient's concerns into 4-6 Main Categories (Level 1)
  * Each category must be distinct and non-overlapping
  * Together, they must cover ALL aspects of the query
  * Examples: "Clinical Presentation", "Diagnostic Investigations", "Management Strategies", "Follow-up Protocol"
- For each Main Category, create 2-3 Sub-categories (Level 2)
  * Each sub-category must be specific and distinct
  * Use descriptive names like "1.1 Symptom Pattern" or "2.1 Recommended Tests"
- For each Sub-category, list 2-3 specific details (Level 3)
  * These are bullet points with actionable information or observations

STEP 3: FORMAT YOUR OUTPUT STRICTLY
- Start IMMEDIATELY with: - **1. $<$Main Category Name$>$**
- Use EXACTLY this format (copy the indentation):
  - **1. $<$Main Category$>$**
    - **1.1 $<$Sub-category$>$**
      - $<$Detail point 1$>$
      - $<$Detail point 2$>$
    - **1.2 $<$Sub-category$>$**
      - $<$Detail point 1$>$
      - $<$Detail point 2$>$
  - **2. $<$Main Category$>$**
    - **2.1 $<$Sub-category$>$**
      - $<$Detail point$>$
      - $<$Detail point$>$
    ...

STEP 4: CONTENT REQUIREMENTS
- Use medical terminology appropriately
- NEVER diagnose definitively (use "Plausible causes", "Possible factors")
- Provide safe, general advice
- Always recommend consulting healthcare providers
- NO introductory text (no "Here is...", "Based on...")
- NO concluding text (no "Hope this helps", "Feel free to ask...")
- Output ONLY the hierarchical bullet list starting with "- **1.""

=== FORMAT VALIDATION CHECKLIST ===
Before outputting, verify:
You start with "- **1." (no text before)
You have 4-6 Main Categories (Level 1, numbered 1, 2, 3...)
Each Main Category has 2-3 Sub-categories (Level 2, numbered 1.1, 1.2...)
Each Sub-category has 2-3 Detail bullets (Level 3, plain bullets)
All Level 1 and Level 2 headers are bolded (**text**)
No overlapping categories (MECE principle)
All patient concerns are addressed (collectively exhaustive)
No diagnosis statements (only plausible causes/advice)

=== FULL EXAMPLE SHOWING FORMAT ===

Input: hi doctor my mom aged 45 years is having a fever for almost two months the temperature used to vary from 100 degrees celsius in the night times and gradually it comes down she was weighing 105 keg and now she is keg now she is having bone pain and light fever in the night when there is a pain in the bone she has been advised with calcium and iron tablets she is also getting her regular periods menopause has not reached yet kindly advise

Output (EXACT FORMAT TO FOLLOW):
- **1. Clinical Presentation Suggestive of Tuberculosis**
    - (output abbreviated)
Input: hi doctor I am having a problem with sinusitis my doctor ordered me to take co altria 10 my at bedtime I have taken it at am and currently I am experiencing dryness of mouth and headache what to do is this serious I am also taking cefixime 200 my twice daily sinupret thrice daily and nasoflo spray

Output:
- **1. Primary Cause of Dry Mouth**
    - (output abbreviated)
    
Input: hello doctor I have erosion in my stomach severe burning sensation and sometimes vomiting and bloating I have done endoscopy colonoscopy angiography and hospitalized for about four times recently again I have done endoscopy found astral erosion please advice

Output:
- **1. Treatment Plan for Gastric Erosion and Ulceration**
  - (output abbreviated)
=== NOW GENERATE YOUR RESPONSE ===

Remember:
1. Start IMMEDIATELY with "- **1." (no introduction)
2. Follow the EXACT format shown in examples above
3. Use 3 levels: Main Category → Sub-category → Details
4. Bold all Level 1 and Level 2 headers with **text**
5. Create 4-6 Main Categories covering all aspects
6. Each Sub-category needs 2-3 detail bullets
7. End after the last bullet (no conclusion)

Input: {{question}}

\end{promptbox}
B. Method for finetuning. Your goal is to finetune two different language models of your choice. You
may choose whether you do full model finetuning or a parameter-efficient tuning method. In your report,
describe your decisionmaking for the hyperparameters and other decisions you made, highlighting key
differences between your choices for the two models. You may choose to use graphs or tables with
comparisons between different approaches to help explain your decisionmaking process.
\section{Problem 3: Experiments}

\begin{table}[h!]
\centering
\begin{tabular}{l c}
\hline
\textbf{Metric} & \textbf{Mean Value} \\
\hline
string\_similarity\_mean      & 0.0246 \\
rouge\_l\_mean                & 0.0494 \\
bleu\_mean                    & 0.00829 \\
mece\_score\_mean             & 0.0399 \\
mece\_compliant\_rate         & 0.0301 \\
depth\_score\_mean            & 0.0693 \\
constraint\_score\_mean       & 0.0422 \\
grouping\_score\_mean         & 0.0230 \\
max\_depth\_mean              & 0.2922 \\ 
total\_points\_mean           & 0.4578 \\
\hline
\end{tabular}
\caption{Evaluation metrics (mean values) Base model}
\end{table}

\begin{table}[h!]
\centering
\begin{tabular}{l c}
\toprule
\textbf{Metric} & \textbf{Mean Value} \\
\midrule
string\_similarity\_mean     & 0.0202 \\
rouge\_l\_mean               & 0.0401 \\
bleu\_mean                   & 0.00730 \\
mece\_score\_mean            & 0.0174 \\
mece\_compliant\_rate        & 0.0151 \\
depth\_score\_mean           & 0.0472 \\
constraint\_score\_mean      & 0.0120 \\
grouping\_score\_mean        & 0.00785 \\
max\_depth\_mean             & 0.1596 \\
total\_points\_mean          & 0.3042 \\
\bottomrule
\end{tabular}
\caption{Overall evaluation metrics (mean values) for 332 samples.}
\end{table}
\subsection{Results for in-context learning}

\subsubsection{Instruct model}

\end{document}